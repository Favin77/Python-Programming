{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Course Project - Animal Detection On Roads\n",
    "\n",
    "### Group Members - Gauravi Dungarwal(31), Favin Fernandes(34), Aishwarya Gaikwad(36), Ishan kareliya(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python Notebook consists the code of Phase 1 (Dataset processing, Feature extraction) & Phase 2 (Training, Testing, Classification, Validation and Recognition)\n",
    "\n",
    "### The Dataset consists of images of 4 classes i.e. Dogs, Cats, Cows & Goats; 101 images each in RGB converted to gray format. The feature descriptor used for this project is SIFT & the classifier used is Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to Memory error 50 images per class is taken for Feature Extraction & Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages,libraries and modules imported and used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre processing & feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to images saved\n",
    "folder1=r\"C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Dataset\\Dog\"\n",
    "folder2=r\"C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Dataset\\Cat\"\n",
    "folder3=r\"C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Dataset\\Cow\"\n",
    "folder4=r\"C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Dataset\\Goats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for Dog images using SIFT\n",
    "i=0\n",
    "for filename in os.listdir(folder1):\n",
    "    if(i==50):\n",
    "        break\n",
    "    #path\n",
    "    path=os.path.join(folder1,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    #gray image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    print(\"descriptor shape \",i,\" : \", out.shape)\n",
    "    i=i+1\n",
    "    \n",
    "    #drop first coloumn as it's the no of feature detected. Not required.\n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('dog.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vector of Dogs Dataset\n",
    "\n",
    "data1 = pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\dog.csv',header=None,dtype='uint8')\n",
    "#MemoryError: Unable to allocate 166. MiB for an array with shape (128, 169606) and data type float64,\n",
    "#Double-precision floating-point format\n",
    "\n",
    "data1=data1.astype(np.uint8) \n",
    "#as unit8 contain 1 byte(8bit) and ranges from 0 to 255\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for Cat images using SIFT\n",
    "i=0\n",
    "for filename in os.listdir(folder2):\n",
    "    if(i==50):\n",
    "        break\n",
    "    \n",
    "    path=os.path.join(folder2,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    print(\"descriptor shape \",i,\" : \", out.shape)\n",
    "    i=i+1\n",
    "    #drop first coloumn as it's the no of feature detected. Not required.\n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('cat.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vector of Cats Dataset\n",
    "data2= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\cat.csv',header=None,dtype='uint8')\n",
    "data2=data2.astype(np.uint8)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for Cow images using SIFT\n",
    "i=0\n",
    "for filename in os.listdir(folder3):\n",
    "    if(i==50):\n",
    "        break\n",
    "    \n",
    "    path=os.path.join(folder3,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    print(\"descriptor shape \",i,\" : \", out.shape)\n",
    "    i=i+1\n",
    "    #drop first coloumn as it's the no of feature detected. Not required.\n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('cow.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vector of Cows Dataset\n",
    "data3= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\cow.csv',header=None,dtype='uint8')\n",
    "data3=data3.astype(np.uint8)\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for Goats images using SIFT\n",
    "i=0\n",
    "for filename in os.listdir(folder4):\n",
    "    if(i==50):\n",
    "        break\n",
    "    \n",
    "    path=os.path.join(folder4,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    print(\"descriptor shape \",i,\" : \", out.shape)\n",
    "    i=i+1\n",
    "    #drop first coloumn as it's the no of feature detected. Not required.\n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('goat.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature vector of Goats Dataset\n",
    "data4= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\goat.csv',header=None,dtype='uint8')\n",
    "data4=data4.astype(np.uint8)\n",
    "#astype(np.uint8) to change the datatype. It is use in order to avoid the memory error\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiled feature vector of 4 Classes\n",
    "\n",
    "data=data1.append(data2)\n",
    "data=data.append(data3)\n",
    "data=data.append(data4)\n",
    "\n",
    "\n",
    "csv_data=data.to_csv('Sift_Final.csv', mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans on each class\n",
    "#Dog\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms of all the classes\n",
    "\n",
    "hist=np.histogram(kmeans.labels_,bins=[0,1,2,3,4,5])\n",
    "\n",
    "\n",
    "print('histogram of trained kmeans')\n",
    "print(hist,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire Dog dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=0\n",
    "data=[]\n",
    "k=0\n",
    "\n",
    "for filename in os.listdir(folder1):\n",
    "    if(k==50):\n",
    "        break\n",
    "    path=os.path.join(folder1,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans.predict(array_double)\n",
    "    \n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    \n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('DogFinal.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire Cat dataset with the pretrained kmeans model\n",
    "\n",
    "#initialising i=1; as its the 2nd class\n",
    "i=1\n",
    "data=[]\n",
    "k=0\n",
    "for filename in os.listdir(folder2):\n",
    "    if(k==50):\n",
    "        break\n",
    "    path=os.path.join(folder2,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float' but got 'double', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('CatFinal.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire Cow dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=2; as its the 3rd class\n",
    "i=2\n",
    "data=[]\n",
    "k=0\n",
    "for filename in os.listdir(folder3):\n",
    "    if(k==50):\n",
    "        break\n",
    "    path=os.path.join(folder3,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float' but got 'double', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    k=k+1\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('CowFinal.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire Goats dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=3; as its the last class\n",
    "i=3\n",
    "data=[]\n",
    "k=0\n",
    "for filename in os.listdir(folder4):\n",
    "    if(k==50):\n",
    "        break\n",
    "    path=os.path.join(folder4,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #predict values of feature vector with pretrained kmeans\n",
    "    #ValueError: Buffer dtype mismatch, expected 'float' but got 'double', in order to avoid this dtype=np.double\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    k=k+1\n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('GoatFinal.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the kmeans predicted data\n",
    "print(\"Dog\")\n",
    "dat1= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\DogFinal.csv',header=None)\n",
    "print(dat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cat\")\n",
    "dat2= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\CatFinal.csv',header=None)\n",
    "print(dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cow\")\n",
    "dat3= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\CowFinal.csv',header=None)\n",
    "print(dat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goat\")\n",
    "dat4= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\GoatFinal.csv',header=None)\n",
    "print(dat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending All classes into 1 csv file\n",
    "\n",
    "A=dat1.append(dat2)\n",
    "A=A.append(dat3)\n",
    "A=A.append(dat4)\n",
    "\n",
    "csv_data=A.to_csv('Final.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ,Testing & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(r'C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Final.csv',header=None)\n",
    "#data.columns=['1','2','3','4','5','Class']\n",
    "#Total no of images = 200\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning x the columns from 1 to 128 for training\n",
    "x = data.iloc[:, 0:5]\n",
    "print(\"X values\")\n",
    "print(x)\n",
    "\n",
    "#assigning y with the column \"Class\" as target variable\n",
    "y = data.iloc[:,5]\n",
    "print(\"Y values\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset split into train and test with 80% Training and 20% Testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assign model with Decision Tree classifier\n",
    "model1 = DecisionTreeClassifier(max_depth=13)\n",
    "#training the model with the Training Variables \n",
    "model1.fit(x_train, y_train)\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = model1.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Save Model\n",
    "pkl_filename = \"Sift1.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model1, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recognition &Validation\n",
    "#Assigning path with any any class image\n",
    "data=[]\n",
    "path=r\"C:\\Users\\francis\\Desktop\\2nd Semester\\CV\\CourseProject\\Dataset\\Dog\\40.jpg\"\n",
    "\n",
    "\n",
    "#Repeated the process of image pre-processing and feature extraction\n",
    "a=cv2.imread(path)\n",
    "resize=(512,512)\n",
    "\n",
    "#resize image\n",
    "img=cv2.resize(a,resize)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#initialise sift descriptor\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "#convert the descriptor array into a dataframe format\n",
    "out=pd.DataFrame(descriptors)\n",
    "print(\"Descriptor Shape:\",out.shape)\n",
    "\n",
    "#initialise Kmeans and create 5 clusters\n",
    "\n",
    "\n",
    "#train the model for the features i.e. for all elements in the Dataframe\n",
    "array_double = np.array(out, dtype=np.double)\n",
    "a=kmeans.predict(array_double)\n",
    "\n",
    "#get the values of the histogram for one image only for 5 clusters i.e. in 5 bins\n",
    "#kmeans.labels_ give us the label vlaue of the feature that its clustered into\n",
    "#hist will give the hostogram for all those vlaues\n",
    "hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "\n",
    "#append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "data.append(hist[0])\n",
    "\n",
    "Output = pd.DataFrame(data)\n",
    "print(\"Histogram:\\n\",Output)\n",
    "\n",
    "cv2.imshow(\"img\",gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the columns 1 to 128 of new image as training variables\n",
    "x = Output.iloc[:, 0:5]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=scaler.transform(x)\n",
    "\n",
    "#prediction\n",
    "y_pred1 = model1.predict(x)\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recognition of image\n",
    "#checking for an class and printing the recognised class  \n",
    "\n",
    "if y_pred1==0:\n",
    "    print(\"Dog\")\n",
    "elif y_pred1==1:\n",
    "    print(\"Cat\")\n",
    "elif y_pred1==2:\n",
    "    print(\"Cow\")  \n",
    "elif y_pred1==3:\n",
    "    print(\"Goat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = \"Sift1.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    Classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(cropped):\n",
    "    data=[]\n",
    "    a=cropped\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    data.append(hist[0])\n",
    "    Output = pd.DataFrame(data) \n",
    "    print(Output)\n",
    "    x = Output.iloc[:, 0:5]\n",
    "    #prediction\n",
    "    y_pred1 = Classifier.predict(x)\n",
    "    return y_pred1\n",
    "\n",
    "def final_class(prediction):\n",
    "    d=\"dog\"\n",
    "    c=\"cat\"\n",
    "    co=\"cow\"\n",
    "    g=\"goat\"\n",
    "    \n",
    "    #loop through predicted output, crosschecked with desired output \n",
    "    if prediction==0:\n",
    "        return d\n",
    "    elif prediction==1:\n",
    "        return c\n",
    "    elif prediction==2:\n",
    "        return co  \n",
    "    elif prediction==3:\n",
    "        return g\n",
    "    \n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "    cropped = frame[bottom_right_y:top_left_y , top_left_x:bottom_right_x]\n",
    "    \n",
    "    prediction =classify(frame)\n",
    "    print(prediction)\n",
    "    \n",
    "    output=final_class(prediction)\n",
    "    print(output)\n",
    "\n",
    "    #cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "    cv2.putText(frame, output,(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "    cv2.imshow('Object Detector using SIFT', frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
